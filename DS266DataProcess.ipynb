{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmcHp1K6qShF",
        "outputId": "b2db64f4-e79b-484d-ef8b-85414f2aac54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wonderwords\n",
            "  Downloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m992.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wonderwords\n",
            "Successfully installed wonderwords-2.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install wonderwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH5E-X5QLJfw"
      },
      "source": [
        "## Setup and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf0nk2Zlogms"
      },
      "outputs": [],
      "source": [
        "## Library imports\n",
        "import requests\n",
        "import json\n",
        "import gzip\n",
        "import io\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import wonderwords\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Other options\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL0jwxnxaZF0"
      },
      "source": [
        "## Data Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nue0iUA0orf9"
      },
      "outputs": [],
      "source": [
        "# NetRunner Cards\n",
        "nr_response = requests.get(\"https://netrunnerdb.com/api/2.0/public/cards\")\n",
        "\n",
        "# Check if the request was successful\n",
        "if nr_response.status_code == 200:\n",
        "    nr_cards = nr_response.json()\n",
        "else:\n",
        "    print(\"Failed to fetch JSON data:\", nr_response.status_code)\n",
        "\n",
        "# Hearthstone Cards\n",
        "hs_response = requests.get(\"https://static.firestoneapp.com/data/cards/cards_enUS.gz.json\")\n",
        "\n",
        "# Check if the request was successful\n",
        "if hs_response.status_code == 200:\n",
        "    hs_cards = hs_response.json()\n",
        "else:\n",
        "    print(\"Failed to fetch JSON data:\", hs_response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyFrtuLHps0f",
        "outputId": "4d9f15b4-5cce-4b30-92c3-4bc25f91efe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'event', 'ice', 'identity', 'operation', 'program', 'resource', 'agenda', 'asset', 'hardware', 'upgrade'}\n",
            "{'nbn', 'sunny-lebeau', 'haas-bioroid', 'anarch', 'apex', 'criminal', 'weyland-consortium', 'shaper', 'adam', 'neutral-runner', 'jinteki', 'neutral-corp'}\n",
            "{'so', 'dc', 'baw', 'cac', 'bf', 'fm', 'sm', 'core', 'atr', 'cd', 'fal', 'rwr', 'es', 'si', 'ftm', 'su21', 'draft', 'uao', 'td', 'rar', 'wla', 'dag', 'tsb', 'dt', 'bb', 'mor', 'oh', 'ml', 'tdc', 'tc', 'fc', 'ur', 'sc19', 'tlm', 'mt', 'kg', 'bm', 'ss', 'mo', 'napd', 'ms', 'fp', 'cc', 'hap', 'ts', 'sg', 'msbp', 'dtwn', 'ta', 'oac', 'tdatd', 'df', 'qu', 'win', 'uot', '23s', 'core2', 'tai', 'urbp', 'ka', 'dad', 'ph', 'hs', 'up', 'uw', 'cotc', 'val', 'st', 'ce', 'asis', 'om', 'eas', 'in'}\n"
          ]
        }
      ],
      "source": [
        "# Check unique card types and classes and see how many are left after limiting to 'normal' cards\n",
        "nr_cards_data = nr_cards['data']\n",
        "unique_types = []\n",
        "unique_classes = []\n",
        "unique_sets = []\n",
        "for item in nr_cards_data:\n",
        "  if 'type_code' in item.keys():\n",
        "    unique_types.append(item['type_code'])\n",
        "  if 'faction_code' in item.keys():\n",
        "    unique_classes.append(item['faction_code'])\n",
        "  if 'pack_code' in item.keys():\n",
        "    unique_sets.append(item['pack_code'])\n",
        "\n",
        "print(set(unique_types))\n",
        "print(set(unique_classes))\n",
        "print(set(unique_sets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svVFBemLam15",
        "outputId": "bff4447f-2d2f-4f74-d081-7cbaaf09358f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Enchantment', 'Lettuce_ability', 'Hero', 'Weapon', 'Game_mode_button', 'Battleground_anomaly', 'Battleground_spell', 'Spell', 'Hero_power', 'Move_minion_hover_target', 'Battleground_quest_reward', 'Location', 'Battleground_hero_buddy', 'Minion'}\n",
            "{'PALADIN', 'HUNTER', 'PRIEST', 'SHAMAN', 'DRUID', 'MAGE', 'ROGUE', 'DEATHKNIGHT', 'DEMONHUNTER', 'WARRIOR', 'WHIZBANG', 'WARLOCK', 'NEUTRAL', 'DREAM'}\n"
          ]
        }
      ],
      "source": [
        "# Check unique card types and classes and see how many are left after limiting to 'normal' cards\n",
        "unique_types = []\n",
        "unique_classes = []\n",
        "for item in hs_cards:\n",
        "  if 'type' in item.keys():\n",
        "    unique_types.append(item['type'])\n",
        "  if 'classes' in item.keys():\n",
        "    for card_class in item['classes']:\n",
        "      unique_classes.append(card_class)\n",
        "\n",
        "print(set(unique_types))\n",
        "print(set(unique_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlBKSNhZtBsO",
        "outputId": "090cc7da-82a7-4a9d-9d07-aa87bc8f1e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'identity': 161, 'event': 264, 'hardware': 163, 'program': 294, 'resource': 257, 'agenda': 204, 'asset': 235, 'operation': 240, 'ice': 364, 'upgrade': 130}\n",
            "['code', 'deck_limit', 'faction_code', 'faction_cost', 'flavor', 'illustrator', 'influence_limit', 'keywords', 'minimum_deck_size', 'pack_code', 'position', 'quantity', 'side_code', 'stripped_text', 'stripped_title', 'text', 'title', 'type_code', 'uniqueness', 'base_link', 'cost', 'memory_cost', 'strength', 'advancement_cost', 'agenda_points', 'trash_cost']\n"
          ]
        }
      ],
      "source": [
        "# Counts by type of card\n",
        "card_types = {}\n",
        "for card in nr_cards_data:\n",
        "  card_type = card['type_code']\n",
        "  if card_type not in card_types.keys():\n",
        "    card_types[card_type] = 1\n",
        "  else:\n",
        "    card_types[card_type] += 1\n",
        "\n",
        "print(card_types)\n",
        "# Based on these counts it seems potentially safe to throw out some of the weird ones\n",
        "\n",
        "# Check each of the unique card keys that appear\n",
        "card_keys = []\n",
        "for card in nr_cards_data:\n",
        "  keyset = card.keys()\n",
        "  for key in keyset:\n",
        "    if not key in card_keys:\n",
        "      card_keys.append(key)\n",
        "print(card_keys)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls-VMpQ2a0gW",
        "outputId": "ee662386-99c0-46e4-913d-f55d83a3bba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cards total: 29254\n",
            "Number of collectible cards total: 6203\n",
            "{'Hero': 465, 'Spell': 1770, 'Minion': 3745, 'Weapon': 198, 'Location': 25}\n",
            "['id', 'dbfId', 'name', 'set', 'cardClass', 'playerClass', 'classes', 'type', 'health', 'collectible', 'faction', 'rarity', 'artist', 'audio2', 'text', 'cost', 'spellSchool', 'flavor', 'attack', 'mechanics', 'race', 'races', 'referencedTags', 'availableAsSignature', 'relatedCardDbfIds', 'durability', 'availableAsDiamond', 'armor', 'questRewardDbfId', 'hideStats', 'enchantmentDbfId', 'deckDuplicateDbfId', 'additionalCosts', 'techLevel']\n"
          ]
        }
      ],
      "source": [
        "# Limit to collectible cards only\n",
        "hs_collectible = [card for card in hs_cards if 'collectible' in card.keys()]\n",
        "print(f\"Number of cards total: {len(hs_cards)}\")\n",
        "print(f\"Number of collectible cards total: {len(hs_collectible)}\")\n",
        "\n",
        "# Counts by type of card\n",
        "card_types = {}\n",
        "for card in hs_collectible:\n",
        "  card_type = card['type']\n",
        "  if card_type not in card_types.keys():\n",
        "    card_types[card_type] = 1\n",
        "  else:\n",
        "    card_types[card_type] += 1\n",
        "\n",
        "print(card_types)\n",
        "# Based on these counts it seems potentially safe to throw out some of the weird ones\n",
        "\n",
        "# Check each of the unique card keys that appear\n",
        "card_keys = []\n",
        "for card in hs_collectible:\n",
        "  keyset = card.keys()\n",
        "  for key in keyset:\n",
        "    if not key in card_keys:\n",
        "      card_keys.append(key)\n",
        "print(card_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ2zixtKGnSv"
      },
      "source": [
        "## Card Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krs235ZbGrnM"
      },
      "source": [
        "### NetRunner cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnex9yHsGkIi",
        "outputId": "64ea5681-d82a-4b1d-d6af-91e7f90ecf05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All cards: 2312\n",
            "Collectible only: 2312\n",
            "Unique cards: 1906\n"
          ]
        }
      ],
      "source": [
        "## CODE TO TURN HS CARDS INTO A DATASET\n",
        "##===========================================================\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "## Choosing which cards to include\n",
        "##-----------------------------------------------------------\n",
        "print(f\"All cards: {len(nr_cards_data)}\")\n",
        "\n",
        "nr_cards_all = pd.DataFrame(nr_cards_data)\n",
        "print(f'Collectible only: {nr_cards_all.shape[0]}')\n",
        "# print(max(nr_cards_all['code'].value_counts())) # non duplicativeness check 1\n",
        "\n",
        "nr_cards_unique = pd.DataFrame(nr_cards_all)\n",
        "nr_cards_unique = nr_cards_unique.sort_values(by='code', ascending=False)\n",
        "nr_cards_unique = nr_cards_unique.drop_duplicates(subset='title', keep='first')\n",
        "print(f'Unique cards: {nr_cards_unique.shape[0]}')\n",
        "\n",
        "# Create the type delineations\n",
        "typecols = pd.get_dummies(nr_cards_unique['type_code'], prefix='type')\n",
        "typecols = typecols.fillna(0)\n",
        "typecols.columns = typecols.columns.str.replace('type_', '')\n",
        "nr_cards_unique = pd.concat([nr_cards_unique, typecols], axis=1)\n",
        "\n",
        "# Keywords need to be split out into their constituent components\n",
        "nr_cards_step1 = nr_cards_unique.copy()\n",
        "nr_cards_step1['keywords'] = nr_cards_step1['keywords'].str.replace('G-mod', 'Gmod', regex=False)\n",
        "nr_cards_step1['keywords'] = nr_cards_step1['keywords'].str.replace('Off-site', 'Offsite', regex=False)\n",
        "nr_cards_step1['keywords'] = nr_cards_step1['keywords'].str.replace('Consumer-grade', 'Consumergrade', regex=False)\n",
        "nr_cards_step1['keywords'] = nr_cards_step1['keywords'].str.replace('Caïssa', 'Caissa', regex=False)\n",
        "nr_cards_step1['keywords'] = nr_cards_step1['keywords'].str.replace(' ', '', regex=False)\n",
        "nr_cards_step1['keywords'].fillna('', inplace=True)\n",
        "split_text = nr_cards_step1['keywords'].str.split('-', expand=True)\n",
        "unique_keywords = set(split_text.values.ravel())\n",
        "for keyword in unique_keywords:\n",
        "  if keyword is not None:\n",
        "    colname = keyword.lower()\n",
        "    nr_cards_step1[colname] = nr_cards_step1['keywords'].str.contains(keyword).astype(int)\n",
        "  nr_cards_step1[colname] = nr_cards_step1[colname].fillna(0)\n",
        "\n",
        "# Several things in the stripped text need to be adjsuted\n",
        "# abilitiy arrows, trace amounts, the names of HQ and R&D, +/- signs\n",
        "nr_cards_step2 = nr_cards_step1.copy()\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('->', 'ability:', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('Trace[', 'Trace [', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('[', ' ', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace(']', ' ', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('HQ', 'headquarters', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('R&D', 'research', regex=False)\n",
        "nr_cards_step2['stripped_text'].fillna('', inplace=True)\n",
        "temp_index = nr_cards_step2['stripped_text'].str.contains(r' -\\d+', regex=True)\n",
        "nr_cards_step2.loc[temp_index, 'stripped_text'] = nr_cards_step2.loc[temp_index, 'stripped_text'].str.replace('-', 'minus ', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('+', 'plus ', regex=False)\n",
        "# Quote abilties are race but a nuisance. Remove them for now\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('\"', '', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('MU', 'mu', regex=False)\n",
        "nr_cards_step2['stripped_text'] = nr_cards_step2['stripped_text'].str.replace('mu', 'memory units', regex=False)\n",
        "\n",
        "# Fill missing values with -1 for cards that have a vlue of NaN\n",
        "nr_cards_step3 = nr_cards_step2.copy()\n",
        "nr_cards_step3['base_link'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['cost'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['memory_cost'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['strength'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['advancement_cost'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['agenda_points'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['trash_cost'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['influence_limit'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['minimum_deck_size'].fillna(-1, inplace=True)\n",
        "nr_cards_step3['deck_limit'].fillna(-1, inplace=True)\n",
        "\n",
        "# other minor adjustments\n",
        "nr_cards_step4 = nr_cards_step3.copy()\n",
        "nr_cards_step4['unique'] = (nr_cards_step4['uniqueness'] == True).astype(int)\n",
        "nr_cards_step4['runner'] = (nr_cards_step4['side_code'] != \"corp\").astype(int)\n",
        "nr_cards_step4['corp'] = (nr_cards_step4['side_code'] == \"corp\").astype(int)\n",
        "nr_cards_step4['influence'] = nr_cards_step4['faction_cost']\n",
        "nr_cards_step4['name'] = nr_cards_step4['title']\n",
        "types = list(set(unique_types))\n",
        "for thistype in types:\n",
        "  nr_cards_step4[thistype] = (nr_cards_step4['type_code'] == thistype).astype(int)\n",
        "\n",
        "# Final column selection\n",
        "nr_cards_clean = nr_cards_step4[['faction_code',\n",
        "                                 # Text fields\n",
        "                                 'name', 'stripped_text',\n",
        "                                 # Key info\n",
        "                                 'runner', 'corp', 'ice', 'upgrade', 'hardware', 'resource', 'identity',\n",
        "                                 'operation', 'agenda', 'program', 'asset', 'event',\n",
        "                                 # Card dscriptors\n",
        "                                 'influence', 'unique', 'cost', 'trash_cost', 'memory_cost', 'strength',\n",
        "                                 'advancement_cost', 'agenda_points', 'base_link',\n",
        "                                 'influence_limit', 'minimum_deck_size', 'deck_limit',\n",
        "                                 # Keywords\n",
        "                                 'morph', 'job', 'location', 'deepnet', 'ambush', 'blackops',\n",
        "                                 'advertisement', 'lockdown', 'codegate', 'enforcer', 'genetics',\n",
        "                                 'sabotage', 'chip', 'source', 'grayops', 'consumergrade', 'division',\n",
        "                                 'priority', 'killer', 'link', 'directive', 'sensie', 'caissa',\n",
        "                                 'trap', 'remote', 'companion', 'deflector', 'hostile', 'vehicle', 'seedy',\n",
        "                                 'bioroid', 'terminal', 'harmonic', 'deva', 'political', 'decoder', 'beanstalk',\n",
        "                                 'psi', 'megacorp', 'cast', 'orgcrime', 'clone', 'reprisal', 'console', 'mythic',\n",
        "                                 'corporation', 'clan', 'grail', 'ai', 'barrier', 'research', 'character', 'trojan',\n",
        "                                 'stealth', 'triple', 'icebreaker', 'academic', 'securityprotocol', 'cyborg',\n",
        "                                 'digital', 'connection', 'transaction', 'ritzy', 'fracter', 'region', 'expendable',\n",
        "                                 'virus', 'expansion', 'offsite', 'industrial', 'daemon', 'virtual', 'observer',\n",
        "                                 'facility', 'current', 'alliance', 'cloud', 'executive', 'condition', 'policedepartment',\n",
        "                                 'weapon', 'destroyer', 'tracer', 'unorthodox', 'natural', 'sentry', 'subsidiary',\n",
        "                                 'security', 'gear', 'sysop', 'next', 'run', 'double', 'gmod', 'ap',\n",
        "                                 'cybernetic', 'initiative', 'illicit', 'mod', 'government', 'public']]\n",
        "\n",
        "# Convert float64 columns to int64\n",
        "float64_columns = nr_cards_clean.select_dtypes(include='float64').columns\n",
        "nr_cards_clean[float64_columns] = nr_cards_clean[float64_columns].astype('int64')\n",
        "\n",
        "## Saving the dataset to look at elsewhere\n",
        "##------------------------------------------------------------\n",
        "# nr_cards_clean.to_csv('nr_cards_clean.csv', index=False)\n",
        "# files.download('nr_cards_clean.csv')\n",
        "\n",
        "# Reset warnings to default behavior\n",
        "warnings.resetwarnings()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLZ1HPrEbUaO"
      },
      "source": [
        "### Hearthstone cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEo-FFb1baAz",
        "outputId": "02490680-5bee-405b-c310-bb4c2a459107"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All cards: 29254\n",
            "Collectible only: 6203\n",
            "After removing reprints: 5092\n",
            "After removing hero skins: 4669\n",
            "After expanding multi-class cards: 4781\n"
          ]
        }
      ],
      "source": [
        "## CODE TO TURN HS CARDS INTO A DATASET\n",
        "##===========================================================\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "## Choosing which cards to include\n",
        "##-----------------------------------------------------------\n",
        "hs_collectible = [card for card in hs_cards if 'collectible' in card.keys()]\n",
        "print(f\"All cards: {len(hs_cards)}\")\n",
        "\n",
        "hs_cards_all = pd.DataFrame(hs_collectible)\n",
        "print(f'Collectible only: {hs_cards_all.shape[0]}')\n",
        "\n",
        "## Remove cards with a non-blank value for deckDuplicateDbfId -- lose ~1000 cards\n",
        "hs_cards_unique = hs_cards_all[hs_cards_all['deckDuplicateDbfId'].isnull()]\n",
        "print(f'After removing reprints: {hs_cards_unique.shape[0]}')\n",
        "\n",
        "## Remove hero cards with no game text, since these are skins only\n",
        "hs_cards_step1 = hs_cards_unique[hs_cards_unique['set'] != 'Hero_skins']\n",
        "print(f'After removing hero skins: {hs_cards_step1.shape[0]}')\n",
        "\n",
        "## Let each multi-class card have multiple copes\n",
        "hs_cards_step2 = hs_cards_step1.explode('classes')\n",
        "print(f'After expanding multi-class cards: {hs_cards_step2.shape[0]}')\n",
        "\n",
        "## Fixing columns and retaining relevant info\n",
        "##-----------------------------------------------------------\n",
        "hs_cards_step3 = hs_cards_step2[['name', 'classes', 'type', 'health', 'cost', 'attack', 'spellSchool', 'races', 'durability', 'armor', 'mechanics', 'text', 'flavor']]\n",
        "\n",
        "## Clean up text fields\n",
        "html_pattern = r'<.*?>'\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace(html_pattern, '', regex=True)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('[x]', '', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('#', '', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('$', '', regex=False)\n",
        "# These three deal with things like 2/2, or +3/+3 to mean health and attack\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('/', ' dash ', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('+', ' plus ', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('-', ' plus ', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('%', ' percent ', regex=False)\n",
        "hs_cards_step3['text'] = hs_cards_step3['text'].str.replace('  ', ' ', regex=False)\n",
        "hs_cards_step3['flavor'] = hs_cards_step3['flavor'].str.replace(html_pattern, '', regex=True)\n",
        "hs_cards_step3['classes'] = hs_cards_step3['classes'].str.replace(\"['\", '', regex=False)\n",
        "hs_cards_step3['classes'] = hs_cards_step3['classes'].str.replace(\"']\", '', regex=False)\n",
        "\n",
        "## Generate Dummy variables\n",
        "##------------------------------------------------------------\n",
        "hs_cards_step4 = hs_cards_step3.copy()\n",
        "\n",
        "# Create extra dummies for the single classification types\n",
        "type_dummies = pd.get_dummies(hs_cards_step4['type'])\n",
        "spell_dummies = pd.get_dummies(hs_cards_step4['spellSchool'])\n",
        "\n",
        "hs_cards_step4 = pd.concat([hs_cards_step4, type_dummies], axis = 1)\n",
        "hs_cards_step4 = pd.concat([hs_cards_step4, spell_dummies], axis = 1)\n",
        "\n",
        "# Fill missing values with -1 for cards that have a vlue of NaN\n",
        "hs_cards_step4['health'].fillna(-1, inplace=True)\n",
        "hs_cards_step4['cost'].fillna(-1, inplace=True)\n",
        "hs_cards_step4['attack'].fillna(-1, inplace=True)\n",
        "hs_cards_step4['durability'].fillna(-1, inplace=True)\n",
        "hs_cards_step4['armor'].fillna(-1, inplace=True)\n",
        "\n",
        "# Special handling for tribe and other key tags\n",
        "# Extract unique race categories\n",
        "def expandMultiCat(in_data, col_name):\n",
        "  out_data = in_data.copy()\n",
        "  unique_categories = set()\n",
        "  # Find all the unique classes within the non-missing entries of the data\n",
        "  missing_rows = pd.isna(out_data[col_name])\n",
        "  vals_list = out_data.loc[[not i for i in missing_rows], col_name]\n",
        "  for item in vals_list:\n",
        "    unique_categories.update(item)\n",
        "  # Set the type of all others to \"none\"\n",
        "  out_data.loc[missing_rows, col_name] = [['NONE']]\n",
        "  # Once the unique categories exist create dummies as needed\n",
        "  for unique_cat in unique_categories:\n",
        "    out_data.loc[:, unique_cat] = out_data[col_name].apply(lambda x: 1 if unique_cat in x else 0)\n",
        "  # Return the fixed dataset\n",
        "  return out_data\n",
        "\n",
        "# Apply special handling to the multi-type sections\n",
        "hs_cards_step5 = expandMultiCat(hs_cards_step4, 'races')\n",
        "hs_cards_step6 = expandMultiCat(hs_cards_step5, 'mechanics')\n",
        "\n",
        "# Keep only a subset of the relevant columns for the modeling exercise\n",
        "hs_cards_features = hs_cards_step6[['classes', # The label of interest\n",
        "                                    # Categorical & numeric features\n",
        "                                    'health', 'cost', 'attack', 'durability', 'armor',\n",
        "                                    # Card types\n",
        "                                    'Hero', 'Location', 'Minion', 'Spell', 'Weapon',\n",
        "                                    # Text features\n",
        "                                    'name', 'text', 'flavor',\n",
        "                                    # Card tribes\n",
        "                                    'MECH', 'QUILBOAR', 'DEMON', 'PIRATE', 'TOTEM', 'NAGA', 'ELEMENTAL', 'ALL', 'BEAST', 'MURLOC', 'DRAGON', 'UNDEAD',\n",
        "                                    # Spell Schools\n",
        "                                    'ARCANE', 'FEL', 'FIRE', 'FROST', 'HOLY', 'NATURE', 'SHADOW',\n",
        "                                    # There are a LOT of mechanics, some appearing on only a few cards\n",
        "                                    # Model will explore the usefulness of adding these\n",
        "                                    'QUICKDRAW', 'COLLECTIONMANAGER_FILTER_MANA_ODD', 'ADJACENT_BUFF', 'GEARS',\n",
        "                                    'DEAL_DAMAGE', 'FORGETFUL', 'MODULAR', 'SECRET', 'ECHO',\n",
        "                                    'MULTIPLY_BUFF_VALUE', 'CHOOSE_ONE', 'FORGE', 'WHELP', 'HONORABLE_KILL',\n",
        "                                    'TWINSPELL', 'QUEST', 'FRENZY', 'OVERHEAL', 'CHARGE', 'FREEZE',\n",
        "                                    'OVERKILL', 'SPELLPOWER', 'DIVINE_SHIELD', 'AFFECTED_BY_SPELL_POWER',\n",
        "                                    'ENRAGED', 'COMBO', 'DEATHRATTLE', 'REBORN', 'CORRUPT', 'HIDE_STATS',\n",
        "                                    'SILENCE', 'TOPDECK', 'POISONOUS', 'WINDFURY', 'TAUNT', 'KABAL',\n",
        "                                    'COLOSSAL', 'GRIMY_GOONS', 'TRADEABLE', 'OVERLOAD', 'INSPIRE',\n",
        "                                    'NON_KEYWORD_ECHO', 'SUMMON', 'EXCAVATE', 'AURA', 'BATTLECRY',\n",
        "                                    'OUTCAST', 'MANATHIRST', 'RUSH', 'HEROPOWER_DAMAGE',\n",
        "                                    'RECEIVES_DOUBLE_SPELLDAMAGE_BONUS', 'JADE_LOTUS', 'FINALE',\n",
        "                                    'DEATH_KNIGHT', 'DREDGE', 'INFUSE',\n",
        "                                    'COLLECTIONMANAGER_FILTER_MANA_EVEN', 'TRIGGER_VISUAL', 'LIFESTEAL',\n",
        "                                    'START_OF_GAME_KEYWORD', 'IMP', 'RESTORE_HEALTH', 'JADE_GOLEM',\n",
        "                                    'DISCOVER', 'STEALTH', 'FINISH_ATTACK_SPELL_ON_DAMAGE']]\n",
        "\n",
        "## Make sure that dummies have the supported int type for random forests\n",
        "int_cols = ['health', 'cost', 'attack', 'durability', 'armor',\n",
        "            'Hero', 'Location', 'Minion', 'Spell', 'Weapon',\n",
        "            'MECH', 'QUILBOAR', 'DEMON', 'PIRATE', 'TOTEM', 'NAGA', 'ELEMENTAL', 'ALL', 'BEAST', 'MURLOC', 'DRAGON', 'UNDEAD',\n",
        "            'ARCANE', 'FEL', 'FIRE', 'FROST', 'HOLY', 'NATURE', 'SHADOW',\n",
        "            'QUICKDRAW', 'COLLECTIONMANAGER_FILTER_MANA_ODD', 'ADJACENT_BUFF', 'GEARS',\n",
        "            'DEAL_DAMAGE', 'FORGETFUL', 'MODULAR', 'SECRET', 'ECHO',\n",
        "            'MULTIPLY_BUFF_VALUE', 'CHOOSE_ONE', 'FORGE', 'WHELP', 'HONORABLE_KILL',\n",
        "            'TWINSPELL', 'QUEST', 'FRENZY', 'OVERHEAL', 'CHARGE', 'FREEZE',\n",
        "            'OVERKILL', 'SPELLPOWER', 'DIVINE_SHIELD', 'AFFECTED_BY_SPELL_POWER',\n",
        "            'ENRAGED', 'COMBO', 'DEATHRATTLE', 'REBORN', 'CORRUPT', 'HIDE_STATS',\n",
        "            'SILENCE', 'TOPDECK', 'POISONOUS', 'WINDFURY', 'TAUNT', 'KABAL',\n",
        "            'COLOSSAL', 'GRIMY_GOONS', 'TRADEABLE', 'OVERLOAD', 'INSPIRE',\n",
        "            'NON_KEYWORD_ECHO', 'SUMMON', 'EXCAVATE', 'AURA', 'BATTLECRY',\n",
        "            'OUTCAST', 'MANATHIRST', 'RUSH', 'HEROPOWER_DAMAGE',\n",
        "            'RECEIVES_DOUBLE_SPELLDAMAGE_BONUS', 'JADE_LOTUS', 'FINALE',\n",
        "            'DEATH_KNIGHT', 'DREDGE', 'INFUSE',\n",
        "            'COLLECTIONMANAGER_FILTER_MANA_EVEN', 'TRIGGER_VISUAL', 'LIFESTEAL',\n",
        "            'START_OF_GAME_KEYWORD', 'IMP', 'RESTORE_HEALTH', 'JADE_GOLEM',\n",
        "            'DISCOVER', 'STEALTH', 'FINISH_ATTACK_SPELL_ON_DAMAGE']\n",
        "hs_cards_features[int_cols] = hs_cards_features[int_cols].astype('int32')\n",
        "\n",
        "## Saving the dataset to look at elsewhere\n",
        "##------------------------------------------------------------\n",
        "# hs_cards_features.to_csv('hs_cards_features.csv', index=False)\n",
        "# files.download('hs_cards_features.csv')\n",
        "\n",
        "# Reset warnings to default behavior\n",
        "warnings.resetwarnings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKNeHibjbefS"
      },
      "source": [
        "## Data Augmentation and adjustments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNX20YxGbhWC"
      },
      "source": [
        "### Netrunner cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCUcCuieDDe0",
        "outputId": "84ee7223-25ee-46fa-804b-d5824b383e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shaper                243\n",
            "criminal              242\n",
            "weyland-consortium    234\n",
            "anarch                234\n",
            "haas-bioroid          228\n",
            "nbn                   220\n",
            "jinteki               216\n",
            "neutral-corp          139\n",
            "neutral-runner        114\n",
            "sunny-lebeau           12\n",
            "apex                   12\n",
            "adam                   12\n",
            "Name: faction_code, dtype: int64\n",
            "neutral-corp          278\n",
            "shaper                243\n",
            "criminal              242\n",
            "weyland-consortium    234\n",
            "anarch                234\n",
            "neutral-runner        228\n",
            "haas-bioroid          228\n",
            "nbn                   220\n",
            "jinteki               216\n",
            "Name: faction_code, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py:522: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  common = np.find_common_type([values.dtype, comps_array.dtype], [])\n"
          ]
        }
      ],
      "source": [
        "## Further data adjustements\n",
        "## The data is highly imbalanced in favor of the netrual cards; easiest way to deal with this seems to be to skip 1 in 4 of them\n",
        "## Alternative would be to double examples of all the other classes\n",
        "value_counts = nr_cards_clean['faction_code'].value_counts()\n",
        "print(value_counts)\n",
        "\n",
        "## The minifactions have significantly fewer cards, to the point that including them is probably not worth it\n",
        "## There are fewer neutrals as well, so we'll double examples for those\n",
        "neutral_corp = nr_cards_clean.loc[nr_cards_clean['faction_code'] == 'neutral-corp']\n",
        "neutral_runner = nr_cards_clean.loc[nr_cards_clean['faction_code'] == 'neutral-runner']\n",
        "nr_cards_nomini = nr_cards_clean.loc[~nr_cards_clean['faction_code'].isin(['apex', 'adam', 'sunny-lebeau'])]\n",
        "\n",
        "## Shuffle the neutrals dataset and drop half\n",
        "nr_cards_data_augment = pd.concat([neutral_corp, neutral_runner, nr_cards_nomini], axis=0)\n",
        "\n",
        "## Re check the counts after data augmentation\n",
        "value_counts_2 = nr_cards_data_augment['faction_code'].value_counts()\n",
        "print(value_counts_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGzHq2jdbpZq"
      },
      "source": [
        "### Hearthstone cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKgkJdEjbqvI",
        "outputId": "b78f810c-a0e5-4833-a041-cdf9223a9b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEUTRAL        1358\n",
            "PRIEST          350\n",
            "WARLOCK         343\n",
            "PALADIN         343\n",
            "ROGUE           342\n",
            "WARRIOR         341\n",
            "MAGE            341\n",
            "SHAMAN          340\n",
            "DRUID           340\n",
            "HUNTER          340\n",
            "DEMONHUNTER     217\n",
            "DEATHKNIGHT     126\n",
            "Name: classes, dtype: int64\n",
            "PRIEST         700\n",
            "WARLOCK        686\n",
            "PALADIN        686\n",
            "ROGUE          684\n",
            "WARRIOR        682\n",
            "MAGE           682\n",
            "SHAMAN         680\n",
            "DRUID          680\n",
            "HUNTER         680\n",
            "NEUTRAL        679\n",
            "DEMONHUNTER    434\n",
            "DEATHKNIGHT    252\n",
            "Name: classes, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "## Further data adjustements\n",
        "## The data is highly imbalanced in favor of the netrual cards; easiest way to deal with this seems to be to skip 1 in 4 of them\n",
        "## Alternative would be to double examples of all the other classes\n",
        "value_counts = hs_cards_features['classes'].value_counts()\n",
        "print(value_counts)\n",
        "\n",
        "## For data augmentation we'll duplicate each example of the class specific cards, and dump half of the neutral cards randomly to try to get better class balance\n",
        "non_neutrals = hs_cards_features.loc[hs_cards_features['classes'] != 'NEUTRAL']\n",
        "neutrals = hs_cards_features.loc[hs_cards_features['classes'] == 'NEUTRAL']\n",
        "## Shuffle the neutrals dataset and drop half\n",
        "shuffled_neutrals = neutrals.sample(frac=1, random_state=2319)\n",
        "num_rows_to_keep = len(shuffled_neutrals) // 2\n",
        "half_dropped_neutrals = shuffled_neutrals.head(num_rows_to_keep)\n",
        "## Stick the datasets back together; the half dropped neutrals and two copies of the non neutrals\n",
        "hs_cards_data_augment = pd.concat([non_neutrals, non_neutrals, half_dropped_neutrals], axis=0)\n",
        "\n",
        "## Re check the counts after data augmentation\n",
        "value_counts_2 = hs_cards_data_augment['classes'].value_counts()\n",
        "print(value_counts_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwDRlYYby1M"
      },
      "source": [
        "## Language model prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpzHPuVxqf3y",
        "outputId": "97e302ed-5315-4d72-96a6-49ee7927f742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "callous interferometer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Random seed word testing\n",
        "from wonderwords import RandomWord\n",
        "seedword = RandomWord()\n",
        "print(seedword.word(include_parts_of_speech=[\"adjectives\"]) + \" \" + seedword.word(include_parts_of_speech=[\"nouns\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wodo7af5b0xE"
      },
      "source": [
        "### Netrunner cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNv6aPcrcBcL",
        "outputId": "ea93742d-98c4-4951-9046-7328db219e6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "## LANGUAGE DATA PREP\n",
        "#===============================================================\n",
        "# The various pieces of the the card need to be stuck together to create something sensible\n",
        "\n",
        "# Constants\n",
        "SUBTYPES = ['morph', 'job', 'location', 'deepnet', 'ambush', 'blackops',\n",
        "            'advertisement', 'lockdown', 'codegate', 'enforcer', 'genetics',\n",
        "            'sabotage', 'chip', 'source', 'grayops', 'consumergrade', 'division',\n",
        "            'priority', 'killer', 'link', 'directive', 'sensie', 'caissa',\n",
        "            'trap', 'remote', 'companion', 'deflector', 'hostile', 'vehicle', 'seedy',\n",
        "            'bioroid', 'terminal', 'harmonic', 'deva', 'political', 'decoder', 'beanstalk',\n",
        "            'psi', 'megacorp', 'cast', 'orgcrime', 'clone', 'reprisal', 'console', 'mythic',\n",
        "            'corporation', 'clan', 'grail', 'ai', 'barrier', 'research', 'character', 'trojan',\n",
        "            'stealth', 'triple', 'icebreaker', 'academic', 'securityprotocol', 'cyborg',\n",
        "            'digital', 'connection', 'transaction', 'ritzy', 'fracter', 'region', 'expendable',\n",
        "            'virus', 'expansion', 'offsite', 'industrial', 'daemon', 'virtual', 'observer',\n",
        "            'facility', 'current', 'alliance', 'cloud', 'executive', 'condition', 'policedepartment',\n",
        "            'weapon', 'destroyer', 'tracer', 'unorthodox', 'natural', 'sentry', 'subsidiary',\n",
        "            'security', 'gear', 'sysop', 'next', 'run', 'double', 'gmod', 'ap',\n",
        "            'cybernetic', 'initiative', 'illicit', 'mod', 'government', 'public']\n",
        "\n",
        "def extendDescription(desc, tag):\n",
        "  if desc == \"\":\n",
        "    desc = desc + tag.lower().replace(\"_\", \" \")\n",
        "  else:\n",
        "    desc = desc + \", \" + tag.lower().replace(\"_\", \" \")\n",
        "  return desc\n",
        "\n",
        "def generateDescriptionNRData(row):\n",
        "  ## Get together the subtype for minions/spell schools, or otherwise\n",
        "  type_modifier = \"\"\n",
        "  stats_modifier = \"\"\n",
        "  desc = f\"The card named {row['name']} is a \"\n",
        "  if row['ice'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost {int(row['strength'])} strength ice \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['program'] == 1:\n",
        "    if row['strength'] > -1:\n",
        "      stren_str = f\"{int(row['strength'])} strength\"\n",
        "    else:\n",
        "      stren_str = f\"\"\n",
        "    desc = desc + f\"{int(row['cost'])} cost {stren_str} program \"\n",
        "    if row['memory_cost'] > -1:\n",
        "      desc = desc + f\"that requires {int(row['memory_cost'])} memory \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['event'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost event \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['operation'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost operation \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['hardware'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost hardware \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['resource'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost resource \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['agenda'] == 1:\n",
        "    desc = desc + f\"{int(row['advancement_cost'])} advancement agenda worth {int(row['agenda_points'])} points \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['asset'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost asset \"\n",
        "    for subtype in SUBTYPES:\n",
        "      if row[subtype] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['upgrade'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost upgrade \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['identity'] == 1:\n",
        "    desc = desc + f\" {int(row['minimum_deck_size'])} deck size identity \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "\n",
        "  ## Influence\n",
        "  if row['identity'] == 1:\n",
        "    desc = desc + f\"It has an influence allotment of {int(row['influence'])}. \"\n",
        "  else:\n",
        "    desc = desc + f\"It has an influence requirement of {int(row['influence'])}. \"\n",
        "\n",
        "  ## Trash costs and game text\n",
        "  if row['trash_cost'] > -1:\n",
        "    desc = desc + f\"It has a trash cost of {int(row['trash_cost'])}. The card text says {row['stripped_text']}.\"\n",
        "  else:\n",
        "    desc = desc + f\"The card text says {row['stripped_text']}.\"\n",
        "\n",
        "  ## Fix spacing and punctuation\n",
        "  desc = desc.replace(\"  \", \" \")\n",
        "  desc = desc.replace(\"..\", \".\")\n",
        "\n",
        "  return desc\n",
        "\n",
        "## t5 peices -----------------------------------------------------------\n",
        "## Code for the t5 name generation\n",
        "def generateGenerateNRData(row):\n",
        "  types = ['ice', 'upgrade', 'hardware', 'resource', 'identity', 'operation', 'agenda', 'program', 'asset', 'event']\n",
        "  thistype = ''\n",
        "  for option in types:\n",
        "    if row[option] == 1:\n",
        "      thistype = option\n",
        "  ## Pull together the pieces of the description\n",
        "  prompt = f\"generate: A {row['faction_code'].lower()}, {thistype} card using seed {seedword.word(include_parts_of_speech=['adjectives'])} {seedword.word(include_parts_of_speech=['nouns'])}.\"\n",
        "  return prompt\n",
        "\n",
        "def generateQuestionNRData(row):\n",
        "  types = ['ice', 'upgrade', 'hardware', 'resource', 'identity', 'operation', 'agenda', 'program', 'asset', 'event']\n",
        "  thistype = ''\n",
        "  for option in types:\n",
        "    if row[option] == 1:\n",
        "      thistype = option\n",
        "  ## Pull together the pieces of the description\n",
        "  prompt = f\"describe card: The {row['faction_code'].lower()}, {thistype} card called {row['name']}.\"\n",
        "  return prompt\n",
        "\n",
        "def generateAnswerNRData(row):\n",
        "  ## Get together the subtype for minions/spell schools, or otherwise\n",
        "  type_modifier = \"\"\n",
        "  stats_modifier = \"\"\n",
        "  desc = f\"This card is a \"\n",
        "  if row['ice'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost {int(row['strength'])} strength ice \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['program'] == 1:\n",
        "    if row['strength'] > -1:\n",
        "      stren_str = f\"{int(row['strength'])} strength\"\n",
        "    else:\n",
        "      stren_str = f\"\"\n",
        "    desc = desc + f\"{int(row['cost'])} cost {stren_str} program \"\n",
        "    if row['memory_cost'] > -1:\n",
        "      desc = desc + f\"that requires {int(row['memory_cost'])} memory \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['event'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost event \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['operation'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost operation \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['hardware'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost hardware \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['resource'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost resource \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['agenda'] == 1:\n",
        "    desc = desc + f\"{int(row['advancement_cost'])} advancement agenda worth {int(row['agenda_points'])} points \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['asset'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost asset \"\n",
        "    for subtype in SUBTYPES:\n",
        "      if row[subtype] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['upgrade'] == 1:\n",
        "    desc = desc + f\"{int(row['cost'])} cost upgrade \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "  elif row['identity'] == 1:\n",
        "    desc = desc + f\" {int(row['minimum_deck_size'])} deck size identity \"\n",
        "    for subtype in SUBTYPES:\n",
        "        if row[subtype] == 1:\n",
        "          type_modifier = extendDescription(type_modifier, subtype)\n",
        "    desc = desc + f\"with the subtypes {type_modifier}. \"\n",
        "\n",
        "  ## Influence\n",
        "  if row['identity'] == 1:\n",
        "    desc = desc + f\"It has an influence allotment of {int(row['influence'])}. \"\n",
        "  else:\n",
        "    desc = desc + f\"It has an influence requirement of {int(row['influence'])}. \"\n",
        "\n",
        "  ## Trash costs and game text\n",
        "  if row['trash_cost'] > -1:\n",
        "    desc = desc + f\"It has a trash cost of {int(row['trash_cost'])}. The card text says {row['stripped_text']}.\"\n",
        "  else:\n",
        "    desc = desc + f\"The card text says {row['stripped_text']}.\"\n",
        "\n",
        "  ## Fix spacing and punctuation\n",
        "  desc = desc.replace(\"  \", \" \")\n",
        "  desc = desc.replace(\"..\", \".\")\n",
        "\n",
        "  return desc\n",
        "\n",
        "nr_cards_data_text = nr_cards_data_augment.copy()\n",
        "nr_cards_data_text['description'] = nr_cards_data_text.apply(lambda row: generateDescriptionNRData(row), axis=1)\n",
        "nr_cards_data_text['t5generate'] = nr_cards_data_text.apply(lambda row: generateGenerateNRData(row), axis=1)\n",
        "nr_cards_data_text['t5prompt'] = nr_cards_data_text.apply(lambda row: generateQuestionNRData(row), axis=1)\n",
        "nr_cards_data_text['t5answer'] = nr_cards_data_text.apply(lambda row: generateAnswerNRData(row), axis=1)\n",
        "nr_cards_data_text.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR3_W8pSb3IH"
      },
      "source": [
        "### Hearthstone cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKpY6p9b5Mn",
        "outputId": "af5750d6-cf43-4756-82f7-1f32237220eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n",
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "## HEARTHSTONE LANGUAGE DATA PREP\n",
        "#===============================================================\n",
        "# The various pieces of the the card need to be stuck together to create something sensible\n",
        "\n",
        "# Constants\n",
        "TRIBES = ['MECH', 'QUILBOAR', 'DEMON', 'PIRATE', 'TOTEM', 'NAGA', 'ELEMENTAL', 'ALL', 'BEAST', 'MURLOC', 'DRAGON', 'UNDEAD']\n",
        "SPELLSCHOOLS = ['ARCANE', 'FEL', 'FIRE', 'FROST', 'HOLY', 'NATURE', 'SHADOW']\n",
        "MECHANICS = ['QUICKDRAW', 'COLLECTIONMANAGER_FILTER_MANA_ODD', 'ADJACENT_BUFF', 'GEARS',\n",
        "            'DEAL_DAMAGE', 'FORGETFUL', 'MODULAR', 'SECRET', 'ECHO',\n",
        "            'MULTIPLY_BUFF_VALUE', 'CHOOSE_ONE', 'FORGE', 'WHELP', 'HONORABLE_KILL',\n",
        "            'TWINSPELL', 'QUEST', 'FRENZY', 'OVERHEAL', 'CHARGE', 'FREEZE',\n",
        "            'OVERKILL', 'SPELLPOWER', 'DIVINE_SHIELD', 'AFFECTED_BY_SPELL_POWER',\n",
        "            'ENRAGED', 'COMBO', 'DEATHRATTLE', 'REBORN', 'CORRUPT', 'HIDE_STATS',\n",
        "            'SILENCE', 'TOPDECK', 'POISONOUS', 'WINDFURY', 'TAUNT', 'KABAL',\n",
        "            'COLOSSAL', 'GRIMY_GOONS', 'TRADEABLE', 'OVERLOAD', 'INSPIRE',\n",
        "            'NON_KEYWORD_ECHO', 'SUMMON', 'EXCAVATE', 'AURA', 'BATTLECRY',\n",
        "            'OUTCAST', 'MANATHIRST', 'RUSH', 'HEROPOWER_DAMAGE',\n",
        "            'RECEIVES_DOUBLE_SPELLDAMAGE_BONUS', 'JADE_LOTUS', 'FINALE',\n",
        "            'DEATH_KNIGHT', 'DREDGE', 'INFUSE',\n",
        "            'COLLECTIONMANAGER_FILTER_MANA_EVEN', 'TRIGGER_VISUAL', 'LIFESTEAL',\n",
        "            'START_OF_GAME_KEYWORD', 'IMP', 'RESTORE_HEALTH', 'JADE_GOLEM',\n",
        "            'DISCOVER', 'STEALTH', 'FINISH_ATTACK_SPELL_ON_DAMAGE']\n",
        "\n",
        "def extendDescription(desc, tag):\n",
        "  if desc == \"\":\n",
        "    desc = desc + tag.lower().replace(\"_\", \" \")\n",
        "  else:\n",
        "    desc = desc + \", \" + tag.lower().replace(\"_\", \" \")\n",
        "  return desc\n",
        "\n",
        "def generateDescriptionHSData(row):\n",
        "  ## Get together the subtype for minions/spell schools, or otherwise\n",
        "  type_modifier = \"\"\n",
        "  stats_modifier = \"\"\n",
        "  if row['Minion'] == 1:\n",
        "    for tribe in TRIBES:\n",
        "      if row[tribe] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, tribe)\n",
        "    type_modifier = type_modifier + \" minion\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['health']} health and {row['attack']} attack\"\n",
        "    if row['armor'] > 0:\n",
        "      stats_modifier = stats_modifier + f\" and {row['armor']} armor\"\n",
        "  elif row['Spell'] == 1:\n",
        "    for spellschool in SPELLSCHOOLS:\n",
        "      if row[spellschool] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, spellschool)\n",
        "    type_modifier = type_modifier + \" spell\"\n",
        "  elif row['Weapon'] == 1:\n",
        "    type_modifier = type_modifier + \" weapon\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['attack']} attack and {row['durability']} durability\"\n",
        "  elif row['Hero'] == 1:\n",
        "    type_modifier = type_modifier + \" hero\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['armor']} armor\"\n",
        "  elif row['Location'] == 1:\n",
        "    type_modifier = type_modifier + \" location\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['health']} health\"\n",
        "  ## Add info about various special mechanics\n",
        "  special_effects = \"\"\n",
        "  has_special_effects = False\n",
        "  for mechanic in MECHANICS:\n",
        "    if row[mechanic] == 1:\n",
        "      has_special_effects = True\n",
        "      special_effects = extendDescription(special_effects, mechanic)\n",
        "  ## Pull together the pieces of the description\n",
        "  finaldesc = f\"The card named {row['name']} is a {row['cost']} cost {type_modifier} {stats_modifier}\"\n",
        "  if has_special_effects:\n",
        "    finaldesc = finaldesc + \", and includes the effects \" + special_effects\n",
        "  cleansed_text = str(row['text']).replace('\\n', ' ')\n",
        "  finaldesc = finaldesc + f\". The card text says: {cleansed_text}\"\n",
        "\n",
        "  return finaldesc\n",
        "\n",
        "## ---------------------------------------------------------\n",
        "## Code for the t5 name generation\n",
        "def generateGenerateHSData(row):\n",
        "  types = ['Hero', 'Location', 'Minion', 'Spell', 'Weapon']\n",
        "  thistype = ''\n",
        "  for option in types:\n",
        "    if row[option] == 1:\n",
        "      thistype = option\n",
        "  ## Pull together the pieces of the description\n",
        "  prompt = f\"generate: A {row['classes'].lower()}, {thistype} card using seed {seedword.word(include_parts_of_speech=['adjectives'])} {seedword.word(include_parts_of_speech=['nouns'])}.\"\n",
        "  return prompt\n",
        "\n",
        "## Code for the t5 generation prompt\n",
        "def generateQuestionHSData(row):\n",
        "  types = ['Hero', 'Location', 'Minion', 'Spell', 'Weapon']\n",
        "  thistype = ''\n",
        "  for option in types:\n",
        "    if row[option] == 1:\n",
        "      thistype = option\n",
        "  ## Pull together the pieces of the description\n",
        "  prompt = f\"describe card: The {row['classes'].lower()}, {thistype} card called {row['name']}.\"\n",
        "  return prompt\n",
        "\n",
        "def generateAnswerHSData(row):\n",
        "  ## Pull together the pieces of the description\n",
        "  type_modifier = \"\"\n",
        "  stats_modifier = \"\"\n",
        "  if row['Minion'] == 1:\n",
        "    for tribe in TRIBES:\n",
        "      if row[tribe] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, tribe)\n",
        "    type_modifier = type_modifier + \" minion\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['health']} health and {row['attack']} attack\"\n",
        "    if row['armor'] > 0:\n",
        "      stats_modifier = stats_modifier + f\" and {row['armor']} armor\"\n",
        "  elif row['Spell'] == 1:\n",
        "    for spellschool in SPELLSCHOOLS:\n",
        "      if row[spellschool] == 1:\n",
        "        type_modifier = extendDescription(type_modifier, spellschool)\n",
        "    type_modifier = type_modifier + \" spell\"\n",
        "  elif row['Weapon'] == 1:\n",
        "    type_modifier = type_modifier + \" weapon\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['attack']} attack and {row['durability']} durability\"\n",
        "  elif row['Hero'] == 1:\n",
        "    type_modifier = type_modifier + \" hero\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['armor']} armor\"\n",
        "  elif row['Location'] == 1:\n",
        "    type_modifier = type_modifier + \" location\"\n",
        "    stats_modifier = stats_modifier + f\"with {row['health']} health\"\n",
        "  ## Add info about various special mechanics\n",
        "  special_effects = \"\"\n",
        "  has_special_effects = False\n",
        "  for mechanic in MECHANICS:\n",
        "    if row[mechanic] == 1:\n",
        "      has_special_effects = True\n",
        "      special_effects = extendDescription(special_effects, mechanic)\n",
        "  ## Pull together the pieces of the description\n",
        "  finaldesc = f\"This card is a {row['cost']} cost {type_modifier} {stats_modifier}\"\n",
        "  if has_special_effects:\n",
        "    finaldesc = finaldesc + \", and includes the effects \" + special_effects\n",
        "  cleansed_text = str(row['text']).replace('\\n', ' ')\n",
        "  finaldesc = finaldesc + f\". The card text says: {cleansed_text}\"\n",
        "\n",
        "  return finaldesc\n",
        "\n",
        "\n",
        "hs_cards_data_text = hs_cards_data_augment.copy()\n",
        "hs_cards_data_text['description'] = hs_cards_data_text.apply(lambda row: generateDescriptionHSData(row), axis=1)\n",
        "hs_cards_data_text['t5generate'] = hs_cards_data_text.apply(lambda row: generateGenerateHSData(row), axis=1)\n",
        "hs_cards_data_text['t5prompt'] = hs_cards_data_text.apply(lambda row: generateQuestionHSData(row), axis=1)\n",
        "hs_cards_data_text['t5answer'] = hs_cards_data_text.apply(lambda row: generateAnswerHSData(row), axis=1)\n",
        "hs_cards_data_text.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn10zxl3_-PF",
        "outputId": "66713c70-d12e-4bc5-a440-9f563dbb194f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "## Specify exact columns to include\n",
        "nr_cards_data_text = nr_cards_data_text[['faction_code',\n",
        "                                         'description',\n",
        "                                         't5generate',\n",
        "                                         't5prompt',\n",
        "                                         't5answer',\n",
        "                                         'name',\n",
        "                                                # Key info\n",
        "                                                'runner', 'corp', 'ice', 'upgrade', 'hardware', 'resource', 'identity',\n",
        "                                                'operation', 'agenda', 'program', 'asset', 'event',\n",
        "                                                # Card dscriptors\n",
        "                                                'influence', 'unique', 'cost', 'trash_cost', 'memory_cost', 'strength',\n",
        "                                                'advancement_cost', 'agenda_points', 'base_link',\n",
        "                                                'influence_limit', 'minimum_deck_size', 'deck_limit',\n",
        "                                                # keywords\n",
        "                                                'morph', 'job', 'location', 'deepnet', 'ambush', 'blackops',\n",
        "                                                'advertisement', 'lockdown', 'codegate', 'enforcer', 'genetics',\n",
        "                                                'sabotage', 'chip', 'source', 'grayops', 'consumergrade', 'division',\n",
        "                                                'priority', 'killer', 'link', 'directive', 'corp', 'sensie', 'caissa',\n",
        "                                                'trap', 'remote', 'companion', 'deflector', 'hostile', 'vehicle', 'seedy',\n",
        "                                                'bioroid', 'terminal', 'harmonic', 'deva', 'political', 'decoder', 'beanstalk',\n",
        "                                                'psi', 'megacorp', 'cast', 'orgcrime', 'clone', 'reprisal', 'console', 'mythic',\n",
        "                                                'corporation', 'clan', 'grail', 'ai', 'barrier', 'research', 'character', 'trojan',\n",
        "                                                'stealth', 'triple', 'icebreaker', 'academic', 'securityprotocol', 'cyborg',\n",
        "                                                'digital', 'connection', 'transaction', 'ritzy', 'fracter', 'region', 'expendable',\n",
        "                                                'virus', 'expansion', 'offsite', 'industrial', 'daemon', 'virtual', 'observer',\n",
        "                                                'facility', 'current', 'alliance', 'cloud', 'executive', 'condition', 'policedepartment',\n",
        "                                                'weapon', 'destroyer', 'tracer', 'unorthodox', 'natural', 'sentry', 'subsidiary',\n",
        "                                                'security', 'gear', 'sysop', 'next', 'run', 'double', 'gmod', 'ap',\n",
        "                                                'cybernetic', 'initiative', 'illicit', 'mod', 'government', 'public']].copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U9x5YAznegV"
      },
      "source": [
        "## Save Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrX5YL-Kz__A",
        "outputId": "f2de9f54-21bd-439b-a39b-eba9c4748a53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Save datasets\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slUcPhAj0nJt",
        "outputId": "95ac801c-cb42-4100-a05c-c25e9f6cc100"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "# Save sets to Google Drive\n",
        "nr_cards_data_augment.to_csv('/content/drive/My Drive/ds266proj/nr_cards_data_augment.csv', index=False)\n",
        "nr_cards_data_text.to_csv('/content/drive/My Drive/ds266proj/nr_cards_data_text.csv', index=False)\n",
        "\n",
        "hs_cards_data_augment.to_csv('/content/drive/My Drive/ds266proj/hs_cards_data_augment.csv', index=False)\n",
        "hs_cards_data_text.to_csv('/content/drive/My Drive/ds266proj/hs_cards_data_text.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip9AqJ18nlO_",
        "outputId": "2ced05dc-6363-4dab-bcad-54f5d0db552a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     generate: A neutral-corp, asset card using seed angry slice.\n",
            "1    generate: A neutral-corp, asset card using seed gigantic min.\n",
            "Name: t5generate, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   print(nr_cards_data_text['description'].head(1))\n",
        "\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   print(hs_cards_data_text['t5answer'].head(1))\n",
        "\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   print(nr_cards_data_text['t5prompt'][455:487])\n",
        "\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   print(hs_cards_data_text['t5prompt'].head(20))\n",
        "\n",
        "# with pd.option_context('display.max_colwidth', None):\n",
        "#   print(nr_cards_data_text['t5generate'].head(2))\n",
        "\n",
        "\n",
        "\n",
        "with pd.option_context('display.max_colwidth', None):\n",
        "  print(nr_cards_data_text['t5generate'].head(2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
