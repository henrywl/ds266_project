{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4HfpWlggVFa",
        "outputId": "eeb9a5f2-0451-4255-ad0b-9edc77d233c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.41.1)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: wonderwords in /usr/local/lib/python3.10/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install numba\n",
        "!pip install accelerate -U\n",
        "!pip install wonderwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_skZNsVPGHS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pPxMgFghE4X"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CedCi01uhFr_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from wonderwords import RandomWord\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import BertModel, T5ForConditionalGeneration, BertTokenizer, T5Tokenizer\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD4u4C5C4nJU",
        "outputId": "0cdd867a-33af-45e1-c296-55c24a07d79e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## Load datasets\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "model_checkpoints_path = '/content/drive/My Drive/ds266proj/model_checkpoints'\n",
        "\n",
        "# Read data from to Google Drive\n",
        "hs_all_data = pd.read_csv('/content/drive/My Drive/ds266proj/hs_cards_data_text.csv')\n",
        "nr_all_data = pd.read_csv('/content/drive/My Drive/ds266proj/nr_cards_data_text.csv')\n",
        "hs_fakes_data = pd.read_csv('/content/drive/My Drive/ds266proj/hs_fakes_withcols.csv')\n",
        "nr_fakes_data = pd.read_csv('/content/drive/My Drive/ds266proj/nr_fakes_withcols.csv')\n",
        "\n",
        "nr_fakes_data = nr_fakes_data[['description', 'faction', 'type']]\n",
        "hs_fakes_data = hs_fakes_data[['description', 'class', 'type']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH-JwIi66Aeg",
        "outputId": "a1f1da70-8780-4aa0-cd16-f7918d772c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         description       faction    type\n",
            "0  The card named Squida is a 3 advancement agend...  neutral-corp  agenda\n",
            "1  The card named \"The Legacy of the Nation\" is a...  neutral-corp  agenda\n",
            "2  The card named The Edge of the Community II is...  neutral-corp  agenda\n",
            "3  The card named Grain is a 5 advancement agenda...  neutral-corp  agenda\n",
            "4  The card named Interpolation is a 3 advancemen...  neutral-corp  agenda\n",
            "                                         description   class   type\n",
            "0  The card named Rift Reap is a 1 cost holy spel...  Priest  Spell\n",
            "1  The card named Dreadspell is a 3 cost spell . ...  Priest  Spell\n",
            "2  The card named Assault on Immortals is a 2 cos...  Priest  Spell\n",
            "3  The card named Shadow Frozen is a 6-cost shado...  Priest  Spell\n",
            "4  The card named Priest of the Night is a 2 cost...  Priest  Spell\n"
          ]
        }
      ],
      "source": [
        "## Add new column for IDing\n",
        "print(nr_fakes_data.head())\n",
        "print(hs_fakes_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "008hs0j47NgZ"
      },
      "outputs": [],
      "source": [
        "## Create the labeled data\n",
        "all_nr_desc = list(nr_all_data['description']) + list(nr_fakes_data['description'])\n",
        "all_hs_desc = list(hs_all_data['description']) + list(hs_fakes_data['description'])\n",
        "\n",
        "nr_labels = [1]*len(nr_all_data) + [0]*len(nr_fakes_data)\n",
        "hs_labels = [1]*len(hs_all_data) + [0]*len(hs_fakes_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymkNqHiF1wQ"
      },
      "source": [
        "## NetRunner\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMzOq9uwF3Zk"
      },
      "source": [
        "### BERT Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z618T5W-8biu",
        "outputId": "bc196276-1115-4726-d7cd-2d6493dab50e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "## Prepare the BERT model to be used for classification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbFmiC0r8nxg"
      },
      "outputs": [],
      "source": [
        "## Tokenize the data\n",
        "nr_tokenized = [tokenizer.encode(description, add_special_tokens=True, max_length=512, truncation=True) for description in all_nr_desc]\n",
        "hs_tokenized = [tokenizer.encode(description, add_special_tokens=True, max_length=512, truncation=True) for description in all_hs_desc]\n",
        "\n",
        "# Ensure all tokenized sequences have the same length by padding shorter sequences\n",
        "max_seq_length_nr = max(len(seq) for seq in nr_tokenized)\n",
        "padded_nr_tokenized = [seq + [0]*(max_seq_length_nr - len(seq)) for seq in nr_tokenized]\n",
        "max_seq_length_hs = max(len(seq) for seq in hs_tokenized)\n",
        "padded_hs_tokenized = [seq + [0]*(max_seq_length_hs - len(seq)) for seq in hs_tokenized]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qj4llto89vC"
      },
      "outputs": [],
      "source": [
        "## Create the dataloader and data to use with the loader\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "class DescriptionData(Dataset):\n",
        "    def __init__(self, tokenized_descriptions, labels):\n",
        "        self.tokenized_descriptions = tokenized_descriptions\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_descriptions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.tokenized_descriptions[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "nr_dataset = DescriptionData(padded_nr_tokenized, nr_labels)\n",
        "hs_dataset = DescriptionData(padded_hs_tokenized, hs_labels)\n",
        "\n",
        "## Prepare the training and test datasets\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "total_size_nr = len(nr_dataset)\n",
        "train_size_nr = int(0.7 * total_size_nr)\n",
        "val_size_nr = total_size_nr - train_size_nr\n",
        "\n",
        "total_size_hs = len(hs_dataset)\n",
        "train_size_hs = int(0.7 * total_size_hs)\n",
        "val_size_hs = total_size_hs - train_size_hs\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_nr_dataset, val_nr_dataset = random_split(nr_dataset, [train_size_nr, val_size_nr])\n",
        "train_hs_dataset, val_hs_dataset = random_split(hs_dataset, [train_size_hs, val_size_hs])\n",
        "\n",
        "# Create dataloaders for training and validation\n",
        "train_nr_dataloader = DataLoader(train_nr_dataset, batch_size=32, shuffle=True)\n",
        "val_nr_dataloader = DataLoader(val_nr_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "train_hs_dataloader = DataLoader(train_hs_dataset, batch_size=32, shuffle=True)\n",
        "val_hs_dataloader = DataLoader(val_hs_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P90bqugY9ZEf"
      },
      "outputs": [],
      "source": [
        "## Create the classifier model\n",
        "class CardDetectiveBERT(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes = 2):\n",
        "        super(CardDetectiveBERT, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc = nn.Linear(bert_model.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUIv7a9ldhUI"
      },
      "source": [
        "### BERT Traininer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6Iq-GNH-LJt"
      },
      "outputs": [],
      "source": [
        "## Instantiate a NR model\n",
        "nr_bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "nr_classifier = CardDetectiveBERT(nr_bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g38BCrnzgEG"
      },
      "outputs": [],
      "source": [
        "## HS Model\n",
        "hs_bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "hs_classifier = CardDetectiveBERT(hs_bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpH5rwE0-YGf",
        "outputId": "ff99faa7-4c5f-4190-f56b-81c09dc69e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8, Avg Batch Loss: 0.4819\n",
            "Epoch 2/8, Avg Batch Loss: 0.2009\n",
            "Epoch 3/8, Avg Batch Loss: 0.0995\n",
            "Epoch 4/8, Avg Batch Loss: 0.0703\n",
            "Epoch 5/8, Avg Batch Loss: 0.0346\n",
            "Epoch 6/8, Avg Batch Loss: 0.0251\n",
            "Epoch 7/8, Avg Batch Loss: 0.0147\n",
            "Epoch 8/8, Avg Batch Loss: 0.0122\n"
          ]
        }
      ],
      "source": [
        "## Define the training loop -- NETRUNNER\n",
        "## PyTorch code developed with some assistance for overall structure using ChatGPT\n",
        "optimizer = torch.optim.Adam(nr_classifier.parameters(), lr=0.00002)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "## Use GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "nr_classifier.to(device)\n",
        "\n",
        "num_epochs = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  nr_classifier.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch in train_nr_dataloader:\n",
        "    ## Load batch with id labels and attention mask\n",
        "    input_ids, labels = batch\n",
        "    input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "\n",
        "    outputs = nr_classifier(input_ids, attention_mask=attention_mask)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  avg_loss = total_loss / len(train_nr_dataloader)\n",
        "  print(f'Epoch {epoch+1}/{num_epochs}, Avg Batch Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYnlSLIB0SpR",
        "outputId": "30f1f7b7-2309-4266-837f-c5797af0e91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8, Avg Batch Loss: 0.5399\n",
            "Epoch 2/8, Avg Batch Loss: 0.3860\n",
            "Epoch 3/8, Avg Batch Loss: 0.1990\n",
            "Epoch 4/8, Avg Batch Loss: 0.0965\n",
            "Epoch 5/8, Avg Batch Loss: 0.0611\n",
            "Epoch 6/8, Avg Batch Loss: 0.0291\n",
            "Epoch 7/8, Avg Batch Loss: 0.0295\n",
            "Epoch 8/8, Avg Batch Loss: 0.0231\n"
          ]
        }
      ],
      "source": [
        "## Define the training loop -- HEARTHSTONE\n",
        "optimizer = torch.optim.Adam(hs_classifier.parameters(), lr=0.00002)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "## Use GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hs_classifier.to(device)\n",
        "\n",
        "num_epochs = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  hs_classifier.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch in train_hs_dataloader:\n",
        "    ## Load batch with id labels and attention mask\n",
        "    input_ids, labels = batch\n",
        "    input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "    attention_mask = (input_ids != 0).long()\n",
        "\n",
        "    outputs = hs_classifier(input_ids, attention_mask=attention_mask)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  avg_loss = total_loss / len(train_hs_dataloader)\n",
        "  print(f'Epoch {epoch+1}/{num_epochs}, Avg Batch Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx0mJSMMGcru"
      },
      "outputs": [],
      "source": [
        "## Save the pre-trained real/fake classifier\n",
        "nr_class_path = model_checkpoints_path + \"/GAN/NetRunner/CardDetectiveBERT.pth\"\n",
        "torch.save(nr_classifier.state_dict(), nr_class_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1ggDJ_I0v-A"
      },
      "outputs": [],
      "source": [
        "## Save the pre-trained real/fake classifier\n",
        "hs_class_path = model_checkpoints_path + \"/GAN/Hearthstone/CardDetectiveBERT.pth\"\n",
        "torch.save(hs_classifier.state_dict(), hs_class_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ll-khzsFth2",
        "outputId": "364d7b04-c6a7-42c5-f399-4b2d8eea8e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on validation set, netrunner: 0.9480\n",
            "Accuracy on validation set, hearthstone: 0.9306\n"
          ]
        }
      ],
      "source": [
        "## Function to compute accuracy\n",
        "def compute_accuracy(model, dataloader):\n",
        "  model.eval()\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        input_ids, labels = batch\n",
        "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "\n",
        "        attention_mask = (input_ids != 0).long()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "  accuracy = correct_predictions / total_predictions\n",
        "  return accuracy\n",
        "\n",
        "# Compute accuracy on the validation set\n",
        "nr_accuracy = compute_accuracy(nr_classifier, val_nr_dataloader)\n",
        "print(f'Accuracy on validation set, netrunner: {nr_accuracy:.4f}')\n",
        "hs_accuracy = compute_accuracy(hs_classifier, val_hs_dataloader)\n",
        "print(f'Accuracy on validation set, hearthstone: {hs_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9aeApsAHl7S",
        "outputId": "b2cd2f1c-e912-4dbc-83df-b12062cb5d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Input: the card named bankroll is a 1 cost program that requires 1 memory with the subtypes. it has an influence requirement of 2. the card text says whenever you make a successful run, you may place 1 credit from the bank on bankroll. trash : take all credits from bankroll.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 2:\n",
            "  Input: the card named netchip is a 1 cost hardware with the subtypes chip, consumergrade. it has an influence requirement of 2. the card text says netchip can host a program with a memory cost less than or equal to the number of copies of netchip installed. the memory cost of the hosted program does not count against your memory limit. limit 6 per deck.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 3:\n",
            "  Input: the card named digital rights management is a 1 cost operation with the subtypes. it has an influence requirement of 1. the card text says play only if the runner did not make a successful run on headquarters during their last turn. search research for 1 agenda and reveal it. ( shuffle research after searching it. ) add that agenda to headquarters. you may install 1 card from headquarters in the root of a remote server. you cannot score agendas for the remainder of the turn.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 4:\n",
            "  Input: the card named ms. duggar is a 2 cost event with the subtypes location. it has an influence requirement of 2. it has a trash cost of 4. the card text says gain 2 credits.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Fake\n",
            "--------------------------------------------------\n",
            "Example 5:\n",
            "  Input: the card named slash and burn agriculture is a 4 advancement agenda worth 2 points with the subtypes expendable, expansion. it has an influence requirement of 0. the card text says click, 1 credit, reveal and trash this agenda from headquarters : place 2 advancement counters on 1 installed card that you can advance.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 1:\n",
            "  Input: the card named drum soloist is a 5 cost dragon minion with 5 health and 5 attack, and includes the effects taunt, battlecry. the card text says : taunt battlecry : if you control no other minions, gain plus 2 dash plus 2 and rush.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 2:\n",
            "  Input: the card named seascout operator is a 3 cost minion with 4 health and 2 attack, and includes the effects battlecry. the card text says : battlecry : if you control a mech, summon two 2 dash 1 mechafish.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 3:\n",
            "  Input: the card named swipe is a 3 cost spell, and includes the effects deal damage. the card text says : deal 4 damage to an enemy and 1 damage to all other enemies.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 4:\n",
            "  Input: the card named mark of y'shaarj is a 2 cost spell. the card text says : give a minion plus 2 dash plus 2. if it's a beast, draw a card.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 5:\n",
            "  Input: the card named sir finley, the intrepid is a 3 cost murloc minion with 3 health and 2 attack, and includes the effects excavate, battlecry. the card text says : battlecry : if you've excavated twice, transform all enemy minions into 1 dash 1 murlocs.\n",
            "  True Label: Real\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "## Code to show some examples\n",
        "def show_examples(model, dataloader, num_examples=5):\n",
        "  model.eval()\n",
        "  examples_shown = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      input_ids, labels = batch\n",
        "      input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "\n",
        "      attention_mask = (input_ids != 0).long()\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "      for i in range(len(predicted)):\n",
        "        print(f'Example {examples_shown + 1}:')\n",
        "        print(f'  Input: {tokenizer.decode(input_ids[i].cpu().numpy(), skip_special_tokens=True)}')\n",
        "        print(f'  True Label: {\"Real\" if labels[i] == 1 else \"Fake\"}')\n",
        "        print(f'  Predicted Label: {\"Real\" if predicted[i] == 1 else \"Fake\"}')\n",
        "        print('-'*50)\n",
        "\n",
        "        examples_shown += 1\n",
        "\n",
        "        if examples_shown >= num_examples:\n",
        "          return\n",
        "\n",
        "# Show some example predictions\n",
        "show_examples(nr_classifier, val_nr_dataloader)\n",
        "show_examples(hs_classifier, val_hs_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggKhe44nJFgh"
      },
      "outputs": [],
      "source": [
        "## Wrong predictions\n",
        "def show_wrong_predictions(model, dataloader, num_examples=5):\n",
        "    model.eval()\n",
        "    wrong_examples = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, labels = batch\n",
        "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "\n",
        "            attention_mask = (input_ids != 0).long()\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            for i in range(len(predicted)):\n",
        "                if predicted[i] != labels[i]:\n",
        "                    wrong_examples.append({\n",
        "                        'input': tokenizer.decode(input_ids[i].cpu().numpy(), skip_special_tokens=True),\n",
        "                        'true_label': \"Real\" if labels[i] == 1 else \"Fake\",\n",
        "                        'predicted_label': \"Real\" if predicted[i] == 1 else \"Fake\"\n",
        "                    })\n",
        "\n",
        "                if len(wrong_examples) >= num_examples:\n",
        "                    return wrong_examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTILHTlM239U",
        "outputId": "48977383-ea42-446c-f229-ac394e3fba09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Input: the card named breakthrough is a 4 advancement agenda worth 2 points with the subtypes agenda. it has an influence requirement of 2. the card text says as an additional cost to play this agenda, spend click. click : subroutine end your run.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 2:\n",
            "  Input: the card named hosted security control is a 3 cost hardware with the subtypes security. it has an influence requirement of 2. the card text says this hardware may not have any effect upon this hardware.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 3:\n",
            "  Input: the card named capstone is a 2 cost hardware with the subtypes. it has an influence requirement of 3. the card text says click : trash any number of cards from your grip. for each trashed card of which you have another copy installed, draw 1 card.\n",
            "  True Label: Real\n",
            "  Predicted Label: Fake\n",
            "--------------------------------------------------\n",
            "Example 4:\n",
            "  Input: the card named xmxx is a 1 cost event having the subtypes. it has an influence requirement of 3. the card text says whenever you breach the security of this server, take 1 tag ; if you did, reveal it. if so, pay 5 credits. you can rez this event.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 5:\n",
            "  Input: the card named xiaoyan is a 3 cost upgrade with the subtypes. it has an influence requirement of 0. it has a trash cost of 3. the card text says when your turn begins, your total cost to steal 2 cards will be increased by 1.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Get wrong predictions from the validation set\n",
        "wrong_predictions = show_wrong_predictions(nr_classifier, val_nr_dataloader)\n",
        "\n",
        "# Print the wrong predictions\n",
        "for i, example in enumerate(wrong_predictions, 1):\n",
        "    print(f'Example {i}:')\n",
        "    print(f'  Input: {example[\"input\"]}')\n",
        "    print(f'  True Label: {example[\"true_label\"]}')\n",
        "    print(f'  Predicted Label: {example[\"predicted_label\"]}')\n",
        "    print('-'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFz7c_Ug26lS",
        "outputId": "1070d4cd-bfba-404f-f497-3dd246e0a819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1:\n",
            "  Input: the card named bloodwok is a 2 cost weapon with 3 attack and 1 durability, and includes the effects deathrattle. the card text says : deathrattle : choose another minion. if your hero died this game, summon it.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 2:\n",
            "  Input: the card named g. h. c. r. e. c. is a 1 cost spell, and includes the effects discover. the card text says : discover a wild boar who died this game.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 3:\n",
            "  Input: the card named spot on the ceiling is a 4 cost spell. the card text says : gain 3 armor.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 4:\n",
            "  Input: the card named windy totem is a 3 cost mech, beast minion with 3 health and 2 attack, and includes the effects trigger visual. the card text says : after a friendly totem dies, summon a new magic spell.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n",
            "Example 5:\n",
            "  Input: the card named powerstroke is a 2 cost fire spell. the card text says : give a minion plus 2 dash plus 3.\n",
            "  True Label: Fake\n",
            "  Predicted Label: Real\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Get wrong predictions from the validation set\n",
        "wrong_predictions = show_wrong_predictions(hs_classifier, val_hs_dataloader)\n",
        "\n",
        "# Print the wrong predictions\n",
        "for i, example in enumerate(wrong_predictions, 1):\n",
        "    print(f'Example {i}:')\n",
        "    print(f'  Input: {example[\"input\"]}')\n",
        "    print(f'  True Label: {example[\"true_label\"]}')\n",
        "    print(f'  Predicted Label: {example[\"predicted_label\"]}')\n",
        "    print('-'*50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
